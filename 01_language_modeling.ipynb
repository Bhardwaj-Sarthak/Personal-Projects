{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhardwaj-Sarthak/Personal-Projects/blob/main/01_language_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMtlGuAVCHuM"
      },
      "source": [
        "# Homework 1: Language models (58 points)\n",
        "\n",
        "The first homework focuses on the following skills: being able to work with concpetual & formal exercises on language modeling and neural networks, understanding configurations of state-of-the-art language models and, finally, fine-tuning a language model yourself!\n",
        "\n",
        "### Logistics\n",
        "\n",
        "* submission deadline: May 13th 23:59 German time via Moodle\n",
        "  * please upload a **SINGLE ZIP FILE named Surname_FirstName_HW1.zip** containing the .ipynb file of the notebook (if you solve it on Colab, you can go to File > download).\n",
        "* please make sure to **KEEP** the outputs of your notebook cells where needed, so that we can inspect them.\n",
        "* please solve and submit the homework **individually**!\n",
        "* if you use Colab, to speed up the execution of the code on Colab (especially Exercise 3), you can use the available GPU (if Colab resources allow). For that, before executing your code, navigate to Runtime > Change runtime type > GPU > Save."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8i9TvKpCHuM"
      },
      "source": [
        "## Exercise 1: Understanding language modeling (12 points)\n",
        "\n",
        "Please answer the following exercises. Importantly, please reason step by step; i.e., where calculations are required, please provide intermediate steps of how you arrived at your solution. You do not need to write any code, just mathematical solutions.\n",
        "\n",
        "> 1. [6pts] Consider the corpus $C$ with the following sentences: $C=${\"The cat sneezes\", \"The bird sings\", \"The cat sneezes\", \"A dog sings\"}.\n",
        "> (a) Define the vocabulary $V$ of this corpus (assuming by-word tokenization).\n",
        "> (b) Pick one of the four sentences in $C$. Formulate the probability of that sentence in the form of the chain rule. Calculate the probability of each termn in the chain rule, given the corpus (assuming that there is, additionally, a start-of-sequence and an end-of-sequence token).\n",
        "> 2. [4pts] We want to train a neural network that takes as input two numbers $x_1, x_2$, passes them through three hidden linear layers, each with 13 neurons, each followed by the ReLU activation function, and outputs three numbers $y_1, y_2, y_3$. Write down all weight matrices of this network with their dimensions. (Example: if one weight matrix has the dimensions 3x5, write $M_1\\in R^{3\\times5}$)\n",
        "> 3. [2pts] Consider the sequence: \"Input: Some students trained each language model\". Assuming that each word+space/punctuation corresponds to one token, consider the following token probabilities of this sequence under some trained language model: $p = [0.67, 0.91, 0.83, 0.40, 0.29, 0.58, 0.75]$. Compute the average surprisal of this sequence under that language model. [Note: in this class we always assume the base $e$ for $log$, unless indicated otherwise. This is also usually the case throughout NLP.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2kz5bKLCHuN"
      },
      "source": [
        "## Exercise 2: Understanding LLM configuration (8 points)\n",
        "\n",
        "For this task, your job is to understand the configrations of a state-of-the-art transformer, provided in a `config.json` file for allowing to initialize a transformer through the function `AutoModelForCausalLM.from_pretrained()` witin the `transformers` library. This file contains meta-information about the parameter configurations of the transformer.\n",
        "\n",
        "Your task is to:\n",
        "1. explain what each line of the following config provides. Please write a commend above the line explaining what the following parameter is.\n",
        "2. modify the config so that the transformer would use a context window size of 1024, 12 attention heads, and a ReLU activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK53htJKCHuN"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"attention_bias\": false,\n",
        "  \"attention_dropout\": 0.0,\n",
        "  \"bos_token_id\": 100257,\n",
        "  \"eos_token_id\": 100257,\n",
        "  \"hidden_act\": \"silu\",\n",
        "  \"hidden_size\": 5120,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 27648,\n",
        "  \"max_position_embeddings\": 4096,\n",
        "  \"num_attention_heads\": 40,\n",
        "  \"num_hidden_layers\": 64,\n",
        "  \"num_key_value_heads\": 8,\n",
        "  \"pad_token_id\": 100277,\n",
        "  \"rms_norm_eps\": 1e-06,\n",
        "  \"rope_scaling\": null,\n",
        "  \"rope_theta\": 500000,\n",
        "  \"tie_word_embeddings\": false,\n",
        "  \"torch_dtype\": \"float32\",\n",
        "  \"use_cache\": true,\n",
        "  \"vocab_size\": 100352\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{  # Whether to use a bias in the attention calculation.\n",
        "  \"attention_bias\": false,\n",
        "  # Dropout rate applied to the attention weights.\n",
        "  \"attention_dropout\": 0.0,\n",
        "  # ID of the beginning-of-sequence token.\n",
        "  \"bos_token_id\": 100257,\n",
        "  # ID of the end-of-sequence token.\n",
        "  \"eos_token_id\": 100257,\n",
        "  # Activation function used in the hidden layers.\n",
        "  \"hidden_act\": \"silu\",\n",
        "  # change this to \"Relu\"\n",
        "\n",
        "  # Dimensionality of the hidden layers.\n",
        "  \"hidden_size\": 5120,\n",
        "  # Standard deviation of the weight initialization.\n",
        "  \"initializer_range\": 0.02,\n",
        "  # Dimensionality of the \"intermediate\" (feed-forward) layer in the transformer block.\n",
        "  \"intermediate_size\": 27648,\n",
        "  # Maximum sequence length the model can handle.\n",
        "  \"max_position_embeddings\": 4096,\n",
        "\n",
        "  # Change this to 1024\n",
        "\n",
        "  # Number of attention heads.\n",
        "  \"num_attention_heads\": 40,\n",
        "  # Change this to 12\n",
        "\n",
        "  # Number of hidden layers in the transformer.\n",
        "  \"num_hidden_layers\": 64,\n",
        "  # Number of key-value heads in the attention mechanism.\n",
        "  \"num_key_value_heads\": 8,\n",
        "  # ID of the padding token.\n",
        "  \"pad_token_id\": 100277,\n",
        "  # Epsilon value used in the root mean square normalization.\n",
        "  \"rms_norm_eps\": 1e-06,\n",
        "  # Scaling factor for the rotary position embeddings (RoPE).\n",
        "  \"rope_scaling\": \"null\",\n",
        "  # Theta value for the rotary position embeddings (RoPE).\n",
        "  \"rope_theta\": 500000,\n",
        "  # Whether to tie the input and output word embeddings.\n",
        "  \"tie_word_embeddings\": False,\n",
        "  # Data type used for the model's parameters.\n",
        "  \"torch_dtype\": \"float32\",\n",
        "  # Whether to use caching during inference.\n",
        "  \"use_cache\": True,\n",
        "  # Size of the model's vocabulary.\n",
        "    \"vocab_size\": 100352 }"
      ],
      "metadata": {
        "id": "Ze3Ag1xCCJpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiZQsQOKCHuO"
      },
      "source": [
        "## Exercise 3 (15 points):\n",
        "\n",
        "In the lecture, we have extensively covered a core component of the transformer -- the self-attention calculation in the forward pass.\n",
        "In this exercise, your task is to perform the forward pass steps 1-6.i (i.e., up to, excluding, the forward step) from the exercise sheet assuming that the transformer has *a second* attention heads, where the second attention head has the following weight matrices:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "co3t38ysCpP8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MZ8ZWW1FCHuO"
      },
      "outputs": [],
      "source": [
        "Q_2 = [[0.5, 1, 1], [2, 0, 0.2], [3, 2, 0]]\n",
        "K_2 = [[0.1, 0.5, 1], [0.5, 1, 1], [2, 2, 2]]\n",
        "V_2 = [[1, 0.1, 0.3], [0, 3, 0.5], [1, 1, 1]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Q_2=torch.tensor(Q_2)\n",
        "K_2=torch.tensor(K_2)\n",
        "V_2=torch.tensor(V_2)\n",
        "I=[[1,0,0,0,0,0,0,0,0,0],\n",
        "   [0,0,0,1,0,0,0,0,0,0],\n",
        "   [0,0,0,0,0,0,1,0,0,0],\n",
        "   [0,0,0,0,0,0,0,1,0,0],\n",
        "   [0,0,1,0,0,0,0,0,0,0]]\n",
        "E=[[0,1,2],\n",
        "   [6,7,1],\n",
        "   [3,4,5],\n",
        "   [0,2,1],\n",
        "   [1,3,0],\n",
        "   [3,8,6],\n",
        "   [2,7,5],\n",
        "   [6,2,1],\n",
        "   [9,1,3],\n",
        "   [0,1,1]]\n",
        "W=[[1,0,1],[0,1,1],[1,1,1]]\n",
        "b_f=[[2],[1],[1]]\n",
        "I=torch.tensor(I,dtype=torch.float32)\n",
        "E=torch.tensor(E,dtype=torch.float32)\n",
        "W=torch.tensor(W,dtype=torch.float32)\n",
        "b_f=torch.tensor(b_f,dtype=torch.float32)\n",
        "print(I.size())\n",
        "print(E.size())\n",
        "X= torch.matmul(I,E)\n",
        "print(X)\n",
        "X_q2=torch.matmul(X,Q_2)\n",
        "print('X*Q2')\n",
        "print(X_q2)\n",
        "X_k2=torch.matmul(X,K_2)\n",
        "print('X*K2')\n",
        "print(X_k2)\n",
        "X_v2=torch.matmul(X,V_2)\n",
        "print('X*V2')\n",
        "print(X_v2)\n",
        "S=torch.tensordot(X_q2,X_k2.T,dims=1)\n",
        "print('S=(X*Q2)(X*K2).T')\n",
        "print(S)\n",
        "A=[[0,-torch.inf,-torch.inf,-torch.inf,-torch.inf],\n",
        "   [0,0,-torch.inf,-torch.inf,-torch.inf],\n",
        "   [0,0,0,-torch.inf,-torch.inf,],\n",
        "   [0,0,0,0,-torch.inf],\n",
        "   [0,0,0,0,0]]\n",
        "A=torch.tensor(A,dtype=torch.float32)\n",
        "print('Mask')\n",
        "print(A)\n",
        "S_A=S+A\n",
        "print(S_A)\n",
        "print('Softmax')\n",
        "z=torch.softmax(S_A,dim=1)\n",
        "print(z)\n",
        "z_v2=torch.matmul(z,X_v2)\n",
        "print('z*V2')\n",
        "print(z_v2)\n",
        "z_v2_sum= z_v2+X\n",
        "print('Sum')\n",
        "print(z_v2_sum)\n",
        "norm_z_v2_sum=torch.nn.functional.normalize(z_v2_sum,p=2,dim=1)\n",
        "print('Norm')\n",
        "print(norm_z_v2_sum)\n",
        "O=torch.matmul(norm_z_v2_sum,W)+b_f.T\n",
        "print('Norm*W+b_f')\n",
        "print(O)\n",
        "M_out=[[0,2,1,1,3,1,0,0,4,1],[1,1,3,1,0,0,4,1,0,2],[1,4,0,0,1,3,1,1,2,0]]\n",
        "M_out=torch.tensor(M_out,dtype=torch.float32)\n",
        "print('M_out')\n",
        "print(M_out)\n",
        "L=torch.matmul(O,M_out)\n",
        "print('L=O*M_out')\n",
        "print(L)\n",
        "print(torch.log(torch.softmax(L,dim=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhPyGy2UCXni",
        "outputId": "db477711-4bf9-4331-9dd8-dc6ecbd4eb8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 10])\n",
            "torch.Size([10, 3])\n",
            "tensor([[0., 1., 2.],\n",
            "        [0., 2., 1.],\n",
            "        [2., 7., 5.],\n",
            "        [6., 2., 1.],\n",
            "        [3., 4., 5.]])\n",
            "X*Q2\n",
            "tensor([[ 8.0000,  4.0000,  0.2000],\n",
            "        [ 7.0000,  2.0000,  0.4000],\n",
            "        [30.0000, 12.0000,  3.4000],\n",
            "        [10.0000,  8.0000,  6.4000],\n",
            "        [24.5000, 13.0000,  3.8000]])\n",
            "X*K2\n",
            "tensor([[ 4.5000,  5.0000,  5.0000],\n",
            "        [ 3.0000,  4.0000,  4.0000],\n",
            "        [13.7000, 18.0000, 19.0000],\n",
            "        [ 3.6000,  7.0000, 10.0000],\n",
            "        [12.3000, 15.5000, 17.0000]])\n",
            "X*V2\n",
            "tensor([[ 2.0000,  5.0000,  2.5000],\n",
            "        [ 1.0000,  7.0000,  2.0000],\n",
            "        [ 7.0000, 26.2000,  9.1000],\n",
            "        [ 7.0000,  7.6000,  3.8000],\n",
            "        [ 8.0000, 17.3000,  7.9000]])\n",
            "S=(X*Q2)(X*K2).T\n",
            "tensor([[ 57.0000,  40.8000, 185.4000,  58.8000, 163.8000],\n",
            "        [ 43.5000,  30.6000, 139.5000,  43.2000, 123.9000],\n",
            "        [212.0000, 151.6000, 691.6000, 226.0000, 612.8000],\n",
            "        [117.0000,  87.6000, 402.6000, 156.0000, 355.8000],\n",
            "        [194.2500, 140.7000, 641.8500, 217.2000, 567.4500]])\n",
            "Mask\n",
            "tensor([[0., -inf, -inf, -inf, -inf],\n",
            "        [0., 0., -inf, -inf, -inf],\n",
            "        [0., 0., 0., -inf, -inf],\n",
            "        [0., 0., 0., 0., -inf],\n",
            "        [0., 0., 0., 0., 0.]])\n",
            "tensor([[ 57.0000,     -inf,     -inf,     -inf,     -inf],\n",
            "        [ 43.5000,  30.6000,     -inf,     -inf,     -inf],\n",
            "        [212.0000, 151.6000, 691.6000,     -inf,     -inf],\n",
            "        [117.0000,  87.6000, 402.6000, 156.0000,     -inf],\n",
            "        [194.2500, 140.7000, 641.8500, 217.2000, 567.4500]])\n",
            "Softmax\n",
            "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 2.4980e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00, 4.8807e-33]])\n",
            "z*V2\n",
            "tensor([[ 2.0000,  5.0000,  2.5000],\n",
            "        [ 2.0000,  5.0000,  2.5000],\n",
            "        [ 7.0000, 26.2000,  9.1000],\n",
            "        [ 7.0000, 26.2000,  9.1000],\n",
            "        [ 7.0000, 26.2000,  9.1000]])\n",
            "Sum\n",
            "tensor([[ 2.0000,  6.0000,  4.5000],\n",
            "        [ 2.0000,  7.0000,  3.5000],\n",
            "        [ 9.0000, 33.2000, 14.1000],\n",
            "        [13.0000, 28.2000, 10.1000],\n",
            "        [10.0000, 30.2000, 14.1000]])\n",
            "Norm\n",
            "tensor([[0.2577, 0.7730, 0.5797],\n",
            "        [0.2476, 0.8666, 0.4333],\n",
            "        [0.2421, 0.8931, 0.3793],\n",
            "        [0.3981, 0.8636, 0.3093],\n",
            "        [0.2874, 0.8679, 0.4052]])\n",
            "Norm*W+b_f\n",
            "tensor([[2.8374, 2.3527, 2.6104],\n",
            "        [2.6809, 2.2999, 2.5475],\n",
            "        [2.6214, 2.2723, 2.5144],\n",
            "        [2.7074, 2.1729, 2.5710],\n",
            "        [2.6926, 2.2731, 2.5605]])\n",
            "M_out\n",
            "tensor([[0., 2., 1., 1., 3., 1., 0., 0., 4., 1.],\n",
            "        [1., 1., 3., 1., 0., 0., 4., 1., 0., 2.],\n",
            "        [1., 4., 0., 0., 1., 3., 1., 1., 2., 0.]])\n",
            "L=O*M_out\n",
            "tensor([[ 4.9631, 18.4691,  9.8956,  5.1901, 11.1226, 10.6686, 12.0213,  4.9631,\n",
            "         16.5704,  7.5429],\n",
            "        [ 4.8473, 17.8515,  9.5805,  4.9807, 10.5901, 10.3233, 11.7469,  4.8473,\n",
            "         15.8185,  7.2806],\n",
            "        [ 4.7867, 17.5728,  9.4384,  4.8937, 10.3785, 10.1646, 11.6037,  4.7867,\n",
            "         15.5143,  7.1660],\n",
            "        [ 4.7440, 17.8719,  9.2262,  4.8804, 10.6933, 10.4206, 11.2627,  4.7440,\n",
            "         15.9718,  7.0533],\n",
            "        [ 4.8336, 17.9001,  9.5118,  4.9657, 10.6382, 10.3740, 11.6528,  4.8336,\n",
            "         15.8913,  7.2388]])\n",
            "tensor([[-13.6480,  -0.1420,  -8.7155, -13.4210,  -7.4885,  -7.9426,  -6.5898,\n",
            "         -13.6480,  -2.0407, -11.0683],\n",
            "        [-13.1305,  -0.1264,  -8.3974, -12.9971,  -7.3877,  -7.6546,  -6.2309,\n",
            "         -13.1305,  -2.1594, -10.6972],\n",
            "        [-12.9099,  -0.1239,  -8.2583, -12.8029,  -7.3181,  -7.5320,  -6.0929,\n",
            "         -12.9099,  -2.1823, -10.5306],\n",
            "        [-13.2699,  -0.1419,  -8.7876, -13.1335,  -7.3205,  -7.5933,  -6.7511,\n",
            "         -13.2699,  -2.0420, -10.9606],\n",
            "        [-13.1955,  -0.1289,  -8.5172, -13.0634,  -7.3908,  -7.6550,  -6.3762,\n",
            "         -13.1955,  -2.1378, -10.7903]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8kK1DnkCHuO"
      },
      "source": [
        "Your task is to submit a solution calculating the contextualized representations of this second attention head.\n",
        "Please make sure to include all the intermediate calculation steps and answer the following question:\n",
        "- How does the memory load of running inference with the transformer scale with the number of attention heads?\n",
        "\n",
        "You can submit a picture / scan of a hand-written, or type it in TeX -- up to you."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "memory load of running inference with the tarnsformer scales **linearly**"
      ],
      "metadata": {
        "id": "kiDeL1RcHt7K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWuJBfOlCHuP"
      },
      "source": [
        "## Exercise 4: Fine-tuning Pythia for Question Answering (23 points)\n",
        "\n",
        "The learning goal of this exercise is to practice fine-tuning a pretrained LM, Pythia-160M, for a particular task, namely commonsense question answering (QA). We will use a task-specific dataset, [CommonsenseQA](https://huggingface.co/datasets/tau/commonsense_qa), that was introduced by [Talmor et al. (2018)](https://arxiv.org/abs/1811.00937). We will evaluate the performance of the model on our test split of the dataset over training to monitor whether the model's performance is improving and compare the performance of the base pretrained Pythia model and the fine-tuned model. We will need to perform the following steps:\n",
        "\n",
        "1. Prepare data according to steps described in [sheet 1.1](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/01-introduction.html#main-training-data-processing-steps)\n",
        "   1. additionally to these steps, prepare a custom Dataset (like in [sheet 2.3](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/02c-MLP-pytorch.html#preparing-the-training-data)) that massages the dataset from the format that it is shipped in on HuggingFace into strings that can be used for training. Some of the procesing steps will happen in the Dataset.\n",
        "2. Load the pretrained Pythia-160m model\n",
        "3. Set up training pipeline according to steps described in [sheet 2.5]()\n",
        "4. Run the training for **200 steps**, while tracking the losses. This number of steps should be sufficient for being able to tell that your training is working *in principle*.\n",
        "5. Save plot of losses for submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi-f5iu-CHuP"
      },
      "source": [
        "Your tasks:\n",
        "> 1. [19pts] Complete the code in the spots where there is a comment \"#### YOUR CODE HERE ####\". There are instructions in the comments as to what the code should implement. With you completed code, you should be able to let the training run without errors. Note that the point of the exercise is the implementation; we should not necessarily expect great performance of the fine-tuned model (and the actual performance will *not* be graded). Often there are several correct ways of implementing something. Anything that is correct will be accepted.\n",
        "> 2. [4pts] Answer questions at the end of the execise."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers datasets langchain-community langchain_nvidia_ai_endpoints==0.3.9 python-dotenv==1.1.0 torchrl llama-index bertviz wikipedia"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_Sdz9caIKjZ",
        "outputId": "9d58e8d2-77bf-4cac-f446-76d6aaa25bab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain_nvidia_ai_endpoints==0.3.9 in /usr/local/lib/python3.11/dist-packages (0.3.9)\n",
            "Requirement already satisfied: python-dotenv==1.1.0 in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: torchrl in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.12.35)\n",
            "Requirement already satisfied: bertviz in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain_nvidia_ai_endpoints==0.3.9) (0.3.59)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from torchrl) (3.1.1)\n",
            "Requirement already satisfied: tensordict<0.9.0,>=0.8.1 in /usr/local/lib/python3.11/dist-packages (from torchrl) (0.8.2)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-cli<0.5,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.1)\n",
            "Requirement already satisfied: llama-index-core<0.13,>=0.12.35 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.12.35)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.6.11)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.38)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.1)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.3.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.7)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.4.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from bertviz) (1.38.14)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bertviz) (0.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints==0.3.9) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: openai>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.77.0)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (2.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.2.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.6.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (11.2.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.13,>=0.12.35->llama-index) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud<0.2.0,>=0.1.13 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.19)\n",
            "Requirement already satisfied: pypdf<6.0.0,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.5.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.7)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.22)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from tensordict<0.9.0,>=0.8.1->torchrl) (8.7.0)\n",
            "Requirement already satisfied: botocore<1.39.0,>=1.38.14 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.38.14)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.13.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from boto3->bertviz) (0.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (1.7.3)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (4.3.8)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints==0.3.9) (3.0.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.22 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.22)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.14.0->llama-index-agent-openai<0.5,>=0.4.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->tensordict<0.9.0,>=0.8.1->torchrl) (3.21.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.0.0->llama-index-core<0.13,>=0.12.35->llama-index) (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AjpdP2XZ8pE",
        "outputId": "6a56a952-4e2a-4c52-f5dd-f3228e1a0b6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.31.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "63KtPjt7CHuP"
      },
      "outputs": [],
      "source": [
        "# note: if you are on Colab, you might need to install some requirements\n",
        "# as we did in Sheet 1.1. Otherwise, don't forget to activate your local environment\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF-8RW8NCHuP",
        "outputId": "85df76ae-ec55-4329-bd22-7d813f307781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "# additioanlly, we need to install accelerate\n",
        "# uncomment and run the following line on Colab or in your environment\n",
        "!pip install accelerate\n",
        "# NOTE: in a notebook, reloading of the kernel might be required after installation if you get dependency errors with the transformers package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TRlKl7_9CHuP"
      },
      "outputs": [],
      "source": [
        "### 1. Prepare data with data prepping steps from sheet 1.1\n",
        "\n",
        "# a. Acquiring data\n",
        "# b. (minimally) exploring dataset\n",
        "# c. cleaning / wrangling data (combines step 4 from sheet 1.1 and step 1.1 above)\n",
        "# d. splitting data into training and validation set (we will not do any hyperparameter tuning)\n",
        "# (we don't need further training set wrangling)\n",
        "# e. tokenizing data and making sure it can be batched (i.e., conversted into 2d tensors)\n",
        "# this will also happen in our custom Dataset class (common practice when working with text data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbarjqfxCHuQ",
        "outputId": "057a7bac-5cf6-4cbd-dbe2-3e2f738af699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# downaload dataset from HF\n",
        "\n",
        "dataset = load_dataset(\"tau/commonsense_qa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9p7Y3S7CHuQ",
        "outputId": "e1f34202-d526-4aab-aec2-e9cd987cfb45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['train', 'validation', 'test'])\n",
            "{'id': ['075e483d21c29a511267ef62bedc0461', '61fe6e879ff18686d7552425a36344c8', '4c1cb0e95b99f72d55c068ba0255c54d', '02e821a3e53cb320790950aab4489e85', '23505889b94e880c3e89cff4ba119860'], 'question': ['The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'Sammy wanted to go to where the people were.  Where might he go?', 'To locate a choker not located in a jewelry box or boutique where would you go?', 'Google Maps and other highway and street GPS services have replaced what?', 'The fox walked from the city into the forest, what was it looking for?'], 'question_concept': ['punishing', 'people', 'choker', 'highway', 'fox'], 'choices': [{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['race track', 'populated areas', 'the desert', 'apartment', 'roadblock']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['jewelry store', 'neck', 'jewlery box', 'jewelry box', 'boutique']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['united states', 'mexico', 'countryside', 'atlas', 'oceans']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['pretty flowers.', 'hen house', 'natural habitat', 'storybook', 'dense forest']}], 'answerKey': ['A', 'B', 'A', 'D', 'C']}\n",
            "{'id': ['1afa02df02c908a558b4036e80242fac', 'a7ab086045575bb497933726e4e6ad28', 'b8c0a4703079cf661d7261a60a1bcbff', 'e68fb2448fd74e402aae9982aa76e527', '2435de612dd69f2012b9e40d6af4ce38'], 'question': ['A revolving door is convenient for two direction travel, but it also serves as a security measure at a what?', 'What do people aim to do at work?', 'Where would you find magazines along side many other printed works?', 'Where are  you likely to find a hamburger?', 'James was looking for a good place to buy farmland.  Where might he look?'], 'question_concept': ['revolving door', 'people', 'magazines', 'hamburger', 'farmland'], 'choices': [{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['bank', 'library', 'department store', 'mall', 'new york']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['complete job', 'learn from each other', 'kill animals', 'wear hats', 'talk to each other']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['doctor', 'bookstore', 'market', 'train station', 'mortuary']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['fast food restaurant', 'pizza', 'ground up dead cows', 'mouth', 'cow carcus']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['midwest', 'countryside', 'estate', 'farming areas', 'illinois']}], 'answerKey': ['A', 'A', 'B', 'A', 'A']}\n",
            "{'id': ['90b30172e645ff91f7171a048582eb8b', '000990552527b1353f98f1e1a7dfc643', 'dca0f2859f3c3dd43a9b2bfeff4936a8', '8795a949b39702af0e452c9e1229046d', '1f74ea1f73b9f5d91a665b4d90218a6e'], 'question': ['The townhouse was a hard sell for the realtor, it was right next to a high rise what?', 'There is a star at the center of what group of celestial bodies?', 'What were the kids doing as they looked up at the sky and clouds?', 'The person taught an advanced class only for who?', 'What is a likely consequence of ignorance of rules?'], 'question_concept': ['townhouse', 'star', 'kids', 'person', 'ignorance'], 'choices': [{'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['suburban development', 'apartment building', 'bus stop', 'michigan', 'suburbs']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['hollywood', 'skyline', 'outer space', 'constellation', 'solar system']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ponder', 'become adults', 'wonder about', 'open door', 'distracting']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['own house', 'own self', 'wonderful memories', 'know truth', 'intelligent children']}, {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['find truth', 'hostility', 'bliss', 'accidents', 'damage']}], 'answerKey': ['', '', '', '', '']}\n"
          ]
        }
      ],
      "source": [
        "# inspect dataset\n",
        "print(dataset.keys())\n",
        "# print a sample from the dataset\n",
        "### YOUR CODE HERE ####\n",
        "train_dataset=dataset[\"train\"]\n",
        "print(train_dataset[:5])\n",
        "val_dataset=dataset[\"validation\"]\n",
        "print(val_dataset[:5])\n",
        "test_dataset=dataset[\"test\"]\n",
        "print(test_dataset[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Ft43i-CHuQ"
      },
      "source": [
        "Note that the test split provided with the dataset does not have ground truth answer labels. Therefore, we will only use the validation split to asssess the performance of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "igGMW3lICHuQ"
      },
      "outputs": [],
      "source": [
        "# load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-160m\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "# set padding side to be left because we are doing causal LM\n",
        "tokenizer.padding_side = \"left\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-clhAkrjCHuQ"
      },
      "outputs": [],
      "source": [
        "def massage_input_text(example):\n",
        "    \"\"\"\n",
        "    Helper for converting input examples which have\n",
        "    a separate qquestion, labels, answer options\n",
        "    into a single string.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    example: dict\n",
        "        Sample input from the dataset which contains the\n",
        "        question, answer labels (e.g. A, B, C, D),\n",
        "        the answer options for the question, and which\n",
        "        of the answers is correct.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    input_text: str\n",
        "        Formatted training text which contains the question,\n",
        "        the forwatted answer options (e.g., 'A. <option 1> B. <option 2>' etc)\n",
        "        and the ground truth answer.\n",
        "    \"\"\"\n",
        "    # combine each label with its corresponding text\n",
        "    answer_options_list = list(zip(\n",
        "        example[\"choices\"][\"label\"],\n",
        "        example[\"choices\"][\"text\"]\n",
        "    ))\n",
        "    # join each label and text with . and space\n",
        "    answer_options = \" \".join([f\"{label}. {text}\" for label, text in answer_options_list])\n",
        "    # join the list of options with spaces into single string\n",
        "    answer_options_string = \" \".join(answer_options.split())\n",
        "    # combine question and answer options\n",
        "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
        "    # append the true answer with a new line, \"Answer: \" and the label\n",
        "    input_text += \" \\nAnswer: \" + example[\"answerKey\"]\n",
        "\n",
        "    return input_text\n",
        "\n",
        "# process input texts of train and validation sets\n",
        "massaged_datasets = dataset.map(\n",
        "    lambda example: {\n",
        "        \"text\": massage_input_text(example)\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sILl3OEoCHuQ",
        "outputId": "ad3720ed-c929-46d9-a065-5234181b0207"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': '075e483d21c29a511267ef62bedc0461',\n",
              " 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?',\n",
              " 'question_concept': 'punishing',\n",
              " 'choices': {'label': ['A', 'B', 'C', 'D', 'E'],\n",
              "  'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']},\n",
              " 'answerKey': 'A',\n",
              " 'text': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? A. ignore B. enforce C. authoritarian D. yell at E. avoid \\nAnswer: A'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# inspect a sample from our preprocessed data\n",
        "massaged_datasets[\"train\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a7128ce404844618b9a07ab0b741e5ee",
            "3e0fcf7810b54e4fad56a5d333c121b6",
            "a0f4eb8628ff4729b5ea325e2dc9e03e",
            "4d661de44f4b4eba8a2f94f102ad04ec",
            "f90988cf3cbb4cb5afdff9b902878372",
            "78f0f12a8b63448db392882f8f152a05",
            "b0ac0eaec0874bf087429024cd17f0b4",
            "49bf00d0b9eb4c04b0849d2d6fd72804",
            "32ea4010f8aa489583037c395f1b81a8",
            "bccb633dbf424e12809816efca8aceb7",
            "2b89249a64114e5aa9b58c136bfb3955"
          ]
        },
        "id": "v5hMmWhjCHuQ",
        "outputId": "2efab1f2-cc32-45e8-cb8a-6d79cf37c742"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1221 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7128ce404844618b9a07ab0b741e5ee"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "def tokenize(tokenizer, example):\n",
        "    \"\"\"\n",
        "    Helper for pre-tokenizing all examples.\n",
        "    \"\"\"\n",
        "    tokenized = tokenizer(\n",
        "        example[\"text\"],\n",
        "        # we are fixing the length to 64 tokens to avoid memory issues\n",
        "        max_length=64,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    return tokenized\n",
        "\n",
        "tokenized_dataset = massaged_datasets.map(\n",
        "    lambda example: tokenize(tokenizer, example),\n",
        "    batched=True,\n",
        "    remove_columns= massaged_datasets[\"train\"].column_names,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9AC5toXCHuQ",
        "outputId": "0a5700c4-8d97-4d05-dd87-02c33b4a0b06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# move to accelerated device\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"Device: {device}\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "    print(f\"Device: {device}\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(f\"Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxjM909MCHuR",
        "outputId": "6c324b1c-247c-4add-cf73-32f090632fd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pythia-160m size: 162.3M parameters\n"
          ]
        }
      ],
      "source": [
        "# 2. init model\n",
        "\n",
        "# load pretrained Pythia-160M for HF\n",
        "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/pythia-160m\")\n",
        "# move model to device\n",
        "model = model.to(device)\n",
        "# print num of trainable parameters\n",
        "model_size = sum(t.numel() for t in model.parameters())\n",
        "print(f\"Pythia-160m size: {model_size/1000**2:.1f}M parameters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OliMHX6pCHuR"
      },
      "source": [
        "Hint: If you run out of memory while trying to run the training, try decreasing the batch size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gpKB0QUyCHuR"
      },
      "outputs": [],
      "source": [
        "# 3. set up configurations required for the training loop\n",
        "\n",
        "# instantiate tokenized train dataset\n",
        "train_dataset = tokenized_dataset[\"train\"]\n",
        "\n",
        "# instantiate tokenized validation dataset\n",
        "validation_dataset = tokenized_dataset['validation']\n",
        "\n",
        "# instantiate a data collator\n",
        "collate_fn = DataCollatorForLanguageModeling(\n",
        "    tokenizer= tokenizer ,\n",
        "    mlm=False\n",
        ")\n",
        "# create a DataLoader for the dataset\n",
        "# the data loader will automatically batch the data\n",
        "# and iteratively return training examples (question answer pairs) in batches\n",
        "dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        ")\n",
        "# create a DataLoader for the test dataset\n",
        "# reason for separate data loader is that we want to\n",
        "# be able to use a different index for retreiving the test batches\n",
        "# we might also want to use a different batch size etc.\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_dataset,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_loss(inputs):\n",
        "  celoss = torch.nn.CrossEntropyLoss()\n",
        "  modelout = outputs[\"logits\"]\n",
        "  # CELoss expects the input to be of shape (batch_size, num_classes, additional_dims)\n",
        "  # So we want to swap the last two dimensions\n",
        "  modelout = torch.permute(modelout, (0, 2, 1))\n",
        "  # create tensor of EOS ids with shape (batch_size*1)\n",
        "  eos_tensor = torch.unsqueeze(torch.tensor([tokenizer.eos_token_id]*inputs[\"labels\"].shape[0]), 1)\n",
        "  eos_tensor = eos_tensor.to(device)\n",
        "  # exclude first input from target labels\n",
        "  target_out = inputs[\"labels\"][:,1:]\n",
        "  target_out = torch.cat((target_out,eos_tensor), dim=1)\n",
        "  loss = celoss(modelout, target_out)\n",
        "  return (loss, outputs)\n",
        "    #vocab_size = logits.size(-1)\n",
        "    #log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "    #labels = labels.view(-1)\n",
        "    #log_probs = log_probs.view(-1, vocab_size)\n",
        "#\n",
        "    #nll_loss = torch.nn.functional.nll_loss(log_probs, labels, reduction='none')\n",
        "    #smooth_loss = -log_probs.mean(dim=-1)\n",
        "    #loss = (1 - epsilon) * nll_loss + epsilon * smooth_loss\n",
        "    #return loss.mean()\n"
      ],
      "metadata": {
        "id": "rsgiK---JZst"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = next(iter(dataloader))\n"
      ],
      "metadata": {
        "id": "ixh1wznYrv5V"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in x.items():\n",
        "    print(k) # dict key\n",
        "    print(v) # values for keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qYBcFCgtcyV",
        "outputId": "add77cb4-dc26-4f56-9d7a-b72aa0a913bd"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids\n",
            "tensor([[    0,     0,     0,  ..., 32869,    27,   399],\n",
            "        [    0,     0,     0,  ..., 32869,    27,   378],\n",
            "        [    0,     0,     0,  ..., 32869,    27,   330],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ..., 32869,    27,   330],\n",
            "        [    0,     0,     0,  ..., 32869,    27,   329],\n",
            "        [    0,     0,     0,  ..., 32869,    27,   329]], device='cuda:0')\n",
            "attention_mask\n",
            "tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1],\n",
            "        [0, 0, 0,  ..., 1, 1, 1]], device='cuda:0')\n",
            "labels\n",
            "tensor([[ -100,  -100,  -100,  ..., 32869,    27,   399],\n",
            "        [ -100,  -100,  -100,  ..., 32869,    27,   378],\n",
            "        [ -100,  -100,  -100,  ..., 32869,    27,   330],\n",
            "        ...,\n",
            "        [ -100,  -100,  -100,  ..., 32869,    27,   330],\n",
            "        [ -100,  -100,  -100,  ..., 32869,    27,   329],\n",
            "        [ -100,  -100,  -100,  ..., 32869,    27,   329]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "obkPQKm2CHuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedfebd8-aff4-42bf-f2a6-bb206a290b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training steps:  200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, step 0, loss 3.7838551998138428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 1/200 [00:00<02:34,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  10.133772659301759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 100/200 [00:29<00:29,  3.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, step 100, loss 3.853119134902954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 101/200 [00:30<00:43,  2.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  3.7999000549316406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:58<00:00,  3.41it/s]\n"
          ]
        }
      ],
      "source": [
        "# 4. run the training of the model\n",
        "# Hint: for implementing the forward pass and loss computation, carefully look at the exercise sheets\n",
        "# and the links to examples in HF tutorials.\n",
        "\n",
        "# put the model in training mode\n",
        "model.train()\n",
        "# move the model to the device (e.g. GPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# trianing configutations\n",
        "# feel free to play around with these\n",
        "epochs  = 1\n",
        "train_steps = 200\n",
        "print(\"Number of training steps: \", train_steps)\n",
        "# number of validation steps to perform every 10 training steps\n",
        "# (smaller than the entire validation split for reasons of comp. time)\n",
        "num_test_steps = 5\n",
        "\n",
        "# define optimizer and learning rate\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
        "# define some variables to accumulate the losses\n",
        "losses = []\n",
        "validation_losses = []\n",
        "\n",
        "# iterate over epochs\n",
        "for e in range(epochs):\n",
        "    # iterate over training steps\n",
        "    for i in tqdm(range(train_steps)):\n",
        "        # get a batch of data\n",
        "        x = next(iter(dataloader))\n",
        "        # move the data to the device (GPU)\n",
        "        x = {k: v.to(device) for k,v in x.items()}\n",
        "\n",
        "        # forward pass through the model\n",
        "\n",
        "        outputs = model(\n",
        "            input_ids = x[\"input_ids\"],\n",
        "            attention_mask = x[\"attention_mask\"],\n",
        "            labels = x[\"labels\"],\n",
        "            return_dict = True\n",
        "        )\n",
        "        # get the loss\n",
        "        #loss = torch.nn.functional.cross_entropy(outputs.logits.view(-1, outputs.logits.shape[-1]), x.labels.view(-1))\n",
        "        #loss = custom_loss(outputs.logits, x.input_ids)\n",
        "        #loss = custom_loss(outputs.logits)\n",
        "        #modouts= outputs['logits']\n",
        "\n",
        "        #criterion = torch.nn.CrossEntropyLoss()\n",
        "        #loss = criterion(outputs.logits.view(-1, outputs.logits.shape[-1]), x[\"labels\"].view(-1))\n",
        "        loss= outputs.loss\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        losses.append(loss.item())\n",
        "        #logits = outputs.logits\n",
        "        #labels = x[\"input_ids\"]\n",
        "        #loss = custom_loss(logits, labels)\n",
        "\n",
        "        # update the parameters of the model\n",
        "        ### YOUR CODE HERE ###\n",
        "        optimizer.step()\n",
        "\n",
        "        # zero out gradient for next step\n",
        "        ### YOUR CODE HERE ####\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # evaluate on a few steps of validation set every 10 steps\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Epoch {e}, step {i}, loss {loss.item()}\")\n",
        "            # track test loss for the evaluation iteration\n",
        "            val_loss = 0\n",
        "            for j in range(num_test_steps):\n",
        "                # get test batch\n",
        "                x_test = next(iter(validation_dataloader))\n",
        "                x_test = x_test.to(device)\n",
        "                with torch.no_grad():\n",
        "                    test_outputs = model(\n",
        "                        input_ids=x_test[\"input_ids\"],\n",
        "                        attention_mask=x_test[\"attention_mask\"],\n",
        "                        labels=x_test[\"labels\"]\n",
        "                        ### YOUR CODE HERE ####\n",
        "                    )\n",
        "                     ### YOUR CODE HERE ####\n",
        "                val_loss += test_outputs.loss.item()\n",
        "\n",
        "            validation_losses.append(val_loss / num_test_steps)\n",
        "            print(\"Test loss: \", val_loss/num_test_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "K3zaIorcCHuR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "be21ad1a-f589-4521-be94-4c8af0734fd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# 5. Plot the fine-tuning loss and MAKE SURE TO SAVE IT AND SUBMIT IT\n",
        "plt.plot(losses)\n",
        "plt.plot(validation_losses)\n",
        "plt.legend([\"Training loss\", \"Validation loss\"])\n",
        "# plot training losses on x axis\n",
        "plt.plot()\n",
        "plt.xlabel(\"Training steps\")\n",
        "plt.ylabel(\"Loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9oO3oTk0CHuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ac44e9-ed99-451f-9a78-a52631604c3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york \\nAnswer:',\n",
              "  'A'),\n",
              " ('What do people aim to do at work? A. complete job B. learn from each other C. kill animals D. wear hats E. talk to each other \\nAnswer:',\n",
              "  'A'),\n",
              " ('Where would you find magazines along side many other printed works? A. doctor B. bookstore C. market D. train station E. mortuary \\nAnswer:',\n",
              "  'B'),\n",
              " ('Where are  you likely to find a hamburger? A. fast food restaurant B. pizza C. ground up dead cows D. mouth E. cow carcus \\nAnswer:',\n",
              "  'A'),\n",
              " ('James was looking for a good place to buy farmland.  Where might he look? A. midwest B. countryside C. estate D. farming areas E. illinois \\nAnswer:',\n",
              "  'A'),\n",
              " ('What island country is ferret popular? A. own home B. north carolina C. great britain D. hutch E. outdoors \\nAnswer:',\n",
              "  'C'),\n",
              " (\"In what Spanish speaking North American country can you get a great cup of coffee? A. mildred's coffee shop B. mexico C. diner D. kitchen E. canteen \\nAnswer:\",\n",
              "  'B'),\n",
              " ('What do animals do when an enemy is approaching? A. feel pleasure B. procreate C. pass water D. listen to each other E. sing \\nAnswer:',\n",
              "  'D'),\n",
              " ('Reading newspaper one of many ways to practice your what? A. literacy B. knowing how to read C. money D. buying E. money bank \\nAnswer:',\n",
              "  'A'),\n",
              " ('What do people typically do while playing guitar? A. cry B. hear sounds C. singing D. arthritis E. making music \\nAnswer:',\n",
              "  'C')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# print a few predictions on the eval dataset to see what the model predicts\n",
        "\n",
        "# construct a list of questions without the ground truth label\n",
        "# and compare prediction of the model with the ground truth\n",
        "\n",
        "def construct_test_samples(example):\n",
        "    \"\"\"\n",
        "    Helper for converting input examples which have\n",
        "    a separate qquestion, labels, answer options\n",
        "    into a single string for testing the model.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    example: dict\n",
        "        Sample input from the dataset which contains the\n",
        "        question, answer labels (e.g. A, B, C, D),\n",
        "        the answer options for the question, and which\n",
        "        of the answers is correct.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    input_text: str, str\n",
        "        Tuple: Formatted test text which contains the question,\n",
        "        the forwatted answer options (e.g., 'A. <option 1> B. <option 2>' etc);\n",
        "        the ground truth answer label only.\n",
        "    \"\"\"\n",
        "\n",
        "    answer_options_list = list(zip(\n",
        "        example[\"choices\"][\"label\"],\n",
        "        example[\"choices\"][\"text\"]\n",
        "    ))\n",
        "    # join each label and text with . and space\n",
        "    answer_options = [f\"{label}. {text}\" for label, text in answer_options_list] ### YOUR CODE HERE ####\n",
        "    # join the list of options with spaces into single string\n",
        "    answer_options_string =\" \".join(answer_options) ### YOUR CODE HERE ####\n",
        "    # combine question and answer options\n",
        "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
        "    # create the test input text which should be:\n",
        "    # the input text, followed by the string \"Answer: \"\n",
        "    # we don't need to append the ground truth answer since we are creating test inputs\n",
        "    # and the answer should be predicted.\n",
        "    input_text += \" \" + \"\\nAnswer:\" ### YOUR CODE HERE ####\n",
        "\n",
        "    return input_text, example[\"answerKey\"]\n",
        "\n",
        "test_samples = [construct_test_samples(dataset[\"validation\"][i]) for i in range(10)]\n",
        "test_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "npb6tO86CHuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969d150c-f535-4707-e2cd-354595ce8c52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions of trained model  [('A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york \\nAnswer:', 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york \\nAnswer: A.', 'A'), ('What do people aim to do at work? A. complete job B. learn from each other C. kill animals D. wear hats E. talk to each other \\nAnswer:', 'What do people aim to do at work? A. complete job B. learn from each other C. kill animals D. wear hats E. talk to each other \\nAnswer: B.', 'A'), ('Where would you find magazines along side many other printed works? A. doctor B. bookstore C. market D. train station E. mortuary \\nAnswer:', 'Where would you find magazines along side many other printed works? A. doctor B. bookstore C. market D. train station E. mortuary \\nAnswer: B.', 'B'), ('Where are  you likely to find a hamburger? A. fast food restaurant B. pizza C. ground up dead cows D. mouth E. cow carcus \\nAnswer:', 'Where are  you likely to find a hamburger? A. fast food restaurant B. pizza C. ground up dead cows D. mouth E. cow carcus \\nAnswer: B.', 'A'), ('James was looking for a good place to buy farmland.  Where might he look? A. midwest B. countryside C. estate D. farming areas E. illinois \\nAnswer:', 'James was looking for a good place to buy farmland.  Where might he look? A. midwest B. countryside C. estate D. farming areas E. illinois \\nAnswer: A.', 'A'), ('What island country is ferret popular? A. own home B. north carolina C. great britain D. hutch E. outdoors \\nAnswer:', 'What island country is ferret popular? A. own home B. north carolina C. great britain D. hutch E. outdoors \\nAnswer: B.', 'C'), (\"In what Spanish speaking North American country can you get a great cup of coffee? A. mildred's coffee shop B. mexico C. diner D. kitchen E. canteen \\nAnswer:\", \"In what Spanish speaking North American country can you get a great cup of coffee? A. mildred's coffee shop B. mexico C. diner D. kitchen E. canteen \\nAnswer: B.\", 'B'), ('What do animals do when an enemy is approaching? A. feel pleasure B. procreate C. pass water D. listen to each other E. sing \\nAnswer:', 'What do animals do when an enemy is approaching? A. feel pleasure B. procreate C. pass water D. listen to each other E. sing \\nAnswer: A.', 'D'), ('Reading newspaper one of many ways to practice your what? A. literacy B. knowing how to read C. money D. buying E. money bank \\nAnswer:', 'Reading newspaper one of many ways to practice your what? A. literacy B. knowing how to read C. money D. buying E. money bank \\nAnswer: A.', 'A'), ('What do people typically do while playing guitar? A. cry B. hear sounds C. singing D. arthritis E. making music \\nAnswer:', 'What do people typically do while playing guitar? A. cry B. hear sounds C. singing D. arthritis E. making music \\nAnswer: A.', 'C')]\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "\n",
        "# set it to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "for sample in test_samples:\n",
        "    input_text = sample[0]\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "    output = model.generate(\n",
        "        input_ids.input_ids,\n",
        "        attention_mask = input_ids.attention_mask,\n",
        "        max_new_tokens=2,\n",
        "        do_sample=True,\n",
        "        temperature=0.4,\n",
        "    )\n",
        "    prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    predictions.append((input_text, prediction, sample[1]))\n",
        "\n",
        "print(\"Predictions of trained model \", predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ankIENZb8Aw0",
        "outputId": "db84eeb8-5239-428a-b84c-d42231259e90"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W14vjFfh8Jek",
        "outputId": "2dc91ba2-4972-48d6-a988-c8ddc8937d69"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york \\nAnswer:',\n",
              "  'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A. bank B. library C. department store D. mall E. new york \\nAnswer: B.',\n",
              "  'A'),\n",
              " ('What do people aim to do at work? A. complete job B. learn from each other C. kill animals D. wear hats E. talk to each other \\nAnswer:',\n",
              "  'What do people aim to do at work? A. complete job B. learn from each other C. kill animals D. wear hats E. talk to each other \\nAnswer: B.',\n",
              "  'A'),\n",
              " ('Where would you find magazines along side many other printed works? A. doctor B. bookstore C. market D. train station E. mortuary \\nAnswer:',\n",
              "  'Where would you find magazines along side many other printed works? A. doctor B. bookstore C. market D. train station E. mortuary \\nAnswer: D.',\n",
              "  'B'),\n",
              " ('Where are  you likely to find a hamburger? A. fast food restaurant B. pizza C. ground up dead cows D. mouth E. cow carcus \\nAnswer:',\n",
              "  'Where are  you likely to find a hamburger? A. fast food restaurant B. pizza C. ground up dead cows D. mouth E. cow carcus \\nAnswer: C.',\n",
              "  'A'),\n",
              " ('James was looking for a good place to buy farmland.  Where might he look? A. midwest B. countryside C. estate D. farming areas E. illinois \\nAnswer:',\n",
              "  'James was looking for a good place to buy farmland.  Where might he look? A. midwest B. countryside C. estate D. farming areas E. illinois \\nAnswer: E.',\n",
              "  'A'),\n",
              " ('What island country is ferret popular? A. own home B. north carolina C. great britain D. hutch E. outdoors \\nAnswer:',\n",
              "  'What island country is ferret popular? A. own home B. north carolina C. great britain D. hutch E. outdoors \\nAnswer: D.',\n",
              "  'C'),\n",
              " (\"In what Spanish speaking North American country can you get a great cup of coffee? A. mildred's coffee shop B. mexico C. diner D. kitchen E. canteen \\nAnswer:\",\n",
              "  \"In what Spanish speaking North American country can you get a great cup of coffee? A. mildred's coffee shop B. mexico C. diner D. kitchen E. canteen \\nAnswer: B.\",\n",
              "  'B'),\n",
              " ('What do animals do when an enemy is approaching? A. feel pleasure B. procreate C. pass water D. listen to each other E. sing \\nAnswer:',\n",
              "  'What do animals do when an enemy is approaching? A. feel pleasure B. procreate C. pass water D. listen to each other E. sing \\nAnswer: D.',\n",
              "  'D'),\n",
              " ('Reading newspaper one of many ways to practice your what? A. literacy B. knowing how to read C. money D. buying E. money bank \\nAnswer:',\n",
              "  'Reading newspaper one of many ways to practice your what? A. literacy B. knowing how to read C. money D. buying E. money bank \\nAnswer: B.',\n",
              "  'A'),\n",
              " ('What do people typically do while playing guitar? A. cry B. hear sounds C. singing D. arthritis E. making music \\nAnswer:',\n",
              "  'What do people typically do while playing guitar? A. cry B. hear sounds C. singing D. arthritis E. making music \\nAnswer: D.',\n",
              "  'C')]"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test model accuracy\n",
        "correct_predictions = 0\n",
        "for input_text, prediction, ground_truth in predictions:\n",
        "    # Extract the predicted answer label (e.g., 'A', 'B', etc.)\n",
        "    predicted_answer = prediction.split(\"Answer:\")[-1].strip()\n",
        "    predicted_answer = predicted_answer.replace(\".\", \"\").strip()\n",
        "    ground_truth = ground_truth.replace(\".\", \"\").strip()\n",
        "    print(f\"model:{predicted_answer}\",\"|\",f\"truth:{ground_truth}\")\n",
        "    if predicted_answer == ground_truth:\n",
        "        correct_predictions += 1\n",
        "\n",
        "accuracy = correct_predictions / len(predictions)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYNe-NnL6u-O",
        "outputId": "22153c5c-56e5-41e8-b935-2d8df2055453"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model:A | truth:A\n",
            "model:B | truth:A\n",
            "model:B | truth:B\n",
            "model:B | truth:A\n",
            "model:A | truth:A\n",
            "model:B | truth:C\n",
            "model:B | truth:B\n",
            "model:A | truth:D\n",
            "model:A | truth:A\n",
            "model:A | truth:C\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ZEwGijCHuR"
      },
      "source": [
        "Questions:\n",
        "> 1. Provide a brief description of the CommonsenseQA dataset. What kind of task was it developed for, what do the single columns contain?\n",
        "> 2. What loss function is computed for this training? Provide the name of the function (conceptual, not necessarily the name of a function in the code).\n",
        "> 3. Given your loss curve, do you think your model will perform well on answering common sense questions? (Note: there is no single right answer; you need to interpret your specific plot)\n",
        "> 4. Inspect the predictions above. On how many test questions did the model predict the right answer? Compute the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBT-k0TdCHuR"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7128ce404844618b9a07ab0b741e5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e0fcf7810b54e4fad56a5d333c121b6",
              "IPY_MODEL_a0f4eb8628ff4729b5ea325e2dc9e03e",
              "IPY_MODEL_4d661de44f4b4eba8a2f94f102ad04ec"
            ],
            "layout": "IPY_MODEL_f90988cf3cbb4cb5afdff9b902878372"
          }
        },
        "3e0fcf7810b54e4fad56a5d333c121b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78f0f12a8b63448db392882f8f152a05",
            "placeholder": "​",
            "style": "IPY_MODEL_b0ac0eaec0874bf087429024cd17f0b4",
            "value": "Map: 100%"
          }
        },
        "a0f4eb8628ff4729b5ea325e2dc9e03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49bf00d0b9eb4c04b0849d2d6fd72804",
            "max": 1221,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32ea4010f8aa489583037c395f1b81a8",
            "value": 1221
          }
        },
        "4d661de44f4b4eba8a2f94f102ad04ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bccb633dbf424e12809816efca8aceb7",
            "placeholder": "​",
            "style": "IPY_MODEL_2b89249a64114e5aa9b58c136bfb3955",
            "value": " 1221/1221 [00:00&lt;00:00, 5146.01 examples/s]"
          }
        },
        "f90988cf3cbb4cb5afdff9b902878372": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f0f12a8b63448db392882f8f152a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0ac0eaec0874bf087429024cd17f0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49bf00d0b9eb4c04b0849d2d6fd72804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32ea4010f8aa489583037c395f1b81a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bccb633dbf424e12809816efca8aceb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b89249a64114e5aa9b58c136bfb3955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}